<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/app/src/main/java/com/geekorum/ttrss/sync/workers/CollectNewArticlesWorker.kt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/app/src/main/java/com/geekorum/ttrss/sync/workers/CollectNewArticlesWorker.kt" />
              <option name="originalContent" value="/*&#10; * Geekttrss is a RSS feed reader application on the Android Platform.&#10; *&#10; * Copyright (C) 2017-2025 by Frederic-Charles Barthelery.&#10; *&#10; * This file is part of Geekttrss.&#10; *&#10; * Geekttrss is free software: you can redistribute it and/or modify&#10; * it under the terms of the GNU General Public License as published by&#10; * the Free Software Foundation, either version 3 of the License, or&#10; * (at your option) any later version.&#10; *&#10; * Geekttrss is distributed in the hope that it will be useful,&#10; * but WITHOUT ANY WARRANTY; without even the implied warranty of&#10; * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the&#10; * GNU General Public License for more details.&#10; *&#10; * You should have received a copy of the GNU General Public License&#10; * along with Geekttrss.  If not, see &lt;http://www.gnu.org/licenses/&gt;.&#10; */&#10;package com.geekorum.ttrss.sync.workers&#10;&#10;import android.accounts.Account&#10;import android.content.Context&#10;import android.content.OperationApplicationException&#10;import android.os.RemoteException&#10;import android.security.NetworkSecurityPolicy&#10;import androidx.hilt.work.HiltWorker&#10;import androidx.work.Data&#10;import androidx.work.WorkerParameters&#10;import androidx.work.workDataOf&#10;import com.geekorum.ttrss.core.CoroutineDispatchersProvider&#10;import com.geekorum.ttrss.data.Article&#10;import com.geekorum.ttrss.data.ArticleWithAttachments&#10;import com.geekorum.ttrss.data.ArticlesTags&#10;import com.geekorum.ttrss.htmlparsers.ImageUrlExtractor&#10;import com.geekorum.ttrss.sync.BackgroundDataUsageManager&#10;import com.geekorum.ttrss.sync.DatabaseService&#10;import com.geekorum.ttrss.sync.HttpCacher&#10;import com.geekorum.ttrss.webapi.ApiCallException&#10;import dagger.assisted.Assisted&#10;import dagger.assisted.AssistedInject&#10;import kotlinx.coroutines.*&#10;import okhttp3.HttpUrl&#10;import okhttp3.HttpUrl.Companion.toHttpUrlOrNull&#10;import timber.log.Timber&#10;import java.io.IOException&#10;&#10;import java.util.concurrent.TimeUnit&#10;&#10;/**&#10; * Collect all the new articles from a feed&#10; */&#10;@HiltWorker&#10;class CollectNewArticlesWorker @AssistedInject constructor(&#10;    @Assisted context: Context,&#10;    @Assisted workerParams: WorkerParameters,&#10;    syncWorkerComponentBuilder: SyncWorkerComponent.Builder,&#10;    private val dispatchers: CoroutineDispatchersProvider,&#10;    private val backgroundDataUsageManager: BackgroundDataUsageManager,&#10;    private val imageUrlExtractor: ImageUrlExtractor,&#10;    private val httpCacher: HttpCacher&#10;) : FeedArticlesWorker(context, workerParams, syncWorkerComponentBuilder) {&#10;&#10;    private val databaseService: DatabaseService = syncWorkerComponent.databaseService&#10;&#10;    companion object {&#10;        const val PARAM_FEED_ID = &quot;feed_id&quot;&#10;&#10;        fun getInputData(account: Account, feedId: Long): Data {&#10;            return workDataOf(&#10;                    SyncWorkerFactory.PARAM_ACCOUNT_NAME to account.name,&#10;                    SyncWorkerFactory.PARAM_ACCOUNT_TYPE to account.type,&#10;                    PARAM_FEED_ID to feedId&#10;            )&#10;        }&#10;    }&#10;&#10;    private var feedId: Long = Long.MIN_VALUE&#10;&#10;    override suspend fun doWork(): Result = withContext(dispatchers.io) {&#10;        feedId = inputData.getLong(PARAM_FEED_ID, Long.MIN_VALUE)&#10;        if (feedId == Long.MIN_VALUE) {&#10;            Timber.w(&quot;No feed_id was specified. Skip work&quot;)&#10;            return@withContext Result.success()&#10;        }&#10;        collectNewArticles()&#10;        Result.success()&#10;    }&#10;&#10;    @Throws(ApiCallException::class, RemoteException::class, OperationApplicationException::class)&#10;    private suspend fun collectNewArticles() = coroutineScope {&#10;        Timber.i(&quot;Collecting new articles for feed $feedId (limit 1 day)&quot;)&#10;        val latestId = getLatestArticleId()&#10;&#10;        var offset = 0&#10;        var totalFetched = 0&#10;        val maxArticlesToFetch = 1000&#10;        val oneDayAgo = System.currentTimeMillis() / 1000 - TimeUnit.DAYS.toSeconds(1)&#10;&#10;        // Fetch newest articles first (gradually=false)&#10;        var articlesRaw = getArticles(feedId, latestId, offset,&#10;            includeAttachments = true, gradually = false)&#10;&#10;        while (articlesRaw.isNotEmpty() &amp;&amp; totalFetched &lt; maxArticlesToFetch) {&#10;            // Filter out articles older than 1 day&#10;            val recentArticles = articlesRaw.filter { it.article.lastTimeUpdate &gt;= oneDayAgo }&#10;&#10;            if (recentArticles.isNotEmpty()) {&#10;                databaseService.runInTransaction {&#10;                    insertArticles(recentArticles)&#10;                }&#10;                totalFetched += recentArticles.size&#10;            }&#10;&#10;            // Check if we reached the end of the &quot;fresh&quot; window&#10;            // If the last article in the batch is older than 1 day, we can stop&#10;            val oldestInBatch = articlesRaw.minByOrNull { it.article.lastTimeUpdate }?.article?.lastTimeUpdate ?: 0&#10;            if (oldestInBatch &lt; oneDayAgo) {&#10;                Timber.i(&quot;Reached articles older than 1 day. Stopping sync for feed $feedId.&quot;)&#10;                break&#10;            }&#10;&#10;            offset += articlesRaw.size&#10;&#10;            if (totalFetched &lt; maxArticlesToFetch) {&#10;                articlesRaw = getArticles(feedId, latestId, offset, includeAttachments = true, gradually = false)&#10;            }&#10;        }&#10;    }&#10;&#10;    private suspend fun getLatestArticleId(): Long {&#10;        return databaseService.getLatestArticleIdFromFeed(feedId) ?: 0&#10;    }&#10;&#10;    private suspend fun insertArticles(articles: List&lt;ArticleWithAttachments&gt;) {&#10;        val articlesOnly = articles.map { it.article }&#10;        databaseService.insertArticles(articlesOnly)&#10;        val articlesTags = articlesOnly.flatMap {&#10;            val tags = it.tags.split(&quot;,&quot;)&#10;                .map(String::trim)&#10;                .filter(String::isNotEmpty)&#10;            tags.map {tag -&gt;&#10;                ArticlesTags(it.id, tag)&#10;            }&#10;        }&#10;        databaseService.insertArticleTags(articlesTags)&#10;        val attachments = articles.flatMap { it.attachments }&#10;        databaseService.insertAttachments(attachments)&#10;    }&#10;&#10;    private fun CoroutineScope.cacheArticlesImages(articles: List&lt;Article&gt;) {&#10;        articles.filter {&#10;            it.isUnread&#10;        }.forEach { cacheArticleImages(it) }&#10;    }&#10;&#10;    private fun CoroutineScope.cacheArticleImages(article: Article) {&#10;        if (!backgroundDataUsageManager.canDownloadArticleImages()) {&#10;            return&#10;        }&#10;        imageUrlExtractor.extract(article.content, baseUri = article.link)&#10;                .mapNotNull { it.toHttpUrlOrNull() }&#10;                .filter { it.canBeCache() }&#10;                .forEach {&#10;                    launch(dispatchers.io) {&#10;                        try {&#10;                            httpCacher.cacheHttpRequest(it)&#10;                        } catch (e: IOException) {&#10;                            Timber.w(e, &quot;Unable to cache request $it&quot;)&#10;                        }&#10;                    }&#10;                }&#10;    }&#10;&#10;    private fun HttpUrl.canBeCache(): Boolean {&#10;        if (scheme == &quot;http&quot; &amp;&amp; !NetworkSecurityPolicy.getInstance().isCleartextTrafficPermitted(host)) {&#10;            Timber.d(&quot;Can't cache $this, clear text traffic not permitted&quot;)&#10;            return false&#10;        }&#10;        return true&#10;    }&#10;&#10;}&#10;" />
              <option name="updatedContent" value="/*&#10; * Geekttrss is a RSS feed reader application on the Android Platform.&#10; *&#10; * Copyright (C) 2017-2025 by Frederic-Charles Barthelery.&#10; *&#10; * This file is part of Geekttrss.&#10; *&#10; * Geekttrss is free software: you can redistribute it and/or modify&#10; * it under the terms of the GNU General Public License as published by&#10; * the Free Software Foundation, either version 3 of the License, or&#10; * (at your option) any later version.&#10; *&#10; * Geekttrss is distributed in the hope that it will be useful,&#10; * but WITHOUT ANY WARRANTY; without even the implied warranty of&#10; * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the&#10; * GNU General Public License for more details.&#10; *&#10; * You should have received a copy of the GNU General Public License&#10; * along with Geekttrss.  If not, see &lt;http://www.gnu.org/licenses/&gt;.&#10; */&#10;package com.geekorum.ttrss.sync.workers&#10;&#10;import android.accounts.Account&#10;import android.content.Context&#10;import android.content.OperationApplicationException&#10;import android.os.RemoteException&#10;import android.security.NetworkSecurityPolicy&#10;import androidx.hilt.work.HiltWorker&#10;import androidx.work.Data&#10;import androidx.work.WorkerParameters&#10;import androidx.work.workDataOf&#10;import com.geekorum.ttrss.core.CoroutineDispatchersProvider&#10;import com.geekorum.ttrss.data.Article&#10;import com.geekorum.ttrss.data.ArticleWithAttachments&#10;import com.geekorum.ttrss.data.ArticlesTags&#10;import com.geekorum.ttrss.htmlparsers.ImageUrlExtractor&#10;import com.geekorum.ttrss.sync.BackgroundDataUsageManager&#10;import com.geekorum.ttrss.sync.DatabaseService&#10;import com.geekorum.ttrss.sync.HttpCacher&#10;import com.geekorum.ttrss.webapi.ApiCallException&#10;import dagger.assisted.Assisted&#10;import dagger.assisted.AssistedInject&#10;import kotlinx.coroutines.*&#10;import okhttp3.HttpUrl&#10;import okhttp3.HttpUrl.Companion.toHttpUrlOrNull&#10;import timber.log.Timber&#10;import java.io.IOException&#10;&#10;import java.util.concurrent.TimeUnit&#10;&#10;/**&#10; * Collect all the new articles from a feed&#10; */&#10;@HiltWorker&#10;class CollectNewArticlesWorker @AssistedInject constructor(&#10;    @Assisted context: Context,&#10;    @Assisted workerParams: WorkerParameters,&#10;    syncWorkerComponentBuilder: SyncWorkerComponent.Builder,&#10;    private val dispatchers: CoroutineDispatchersProvider,&#10;    private val backgroundDataUsageManager: BackgroundDataUsageManager,&#10;    private val imageUrlExtractor: ImageUrlExtractor,&#10;    private val httpCacher: HttpCacher&#10;) : FeedArticlesWorker(context, workerParams, syncWorkerComponentBuilder) {&#10;&#10;    private val databaseService: DatabaseService = syncWorkerComponent.databaseService&#10;&#10;    companion object {&#10;        const val PARAM_FEED_ID = &quot;feed_id&quot;&#10;&#10;        fun getInputData(account: Account, feedId: Long): Data {&#10;            return workDataOf(&#10;                    SyncWorkerFactory.PARAM_ACCOUNT_NAME to account.name,&#10;                    SyncWorkerFactory.PARAM_ACCOUNT_TYPE to account.type,&#10;                    PARAM_FEED_ID to feedId&#10;            )&#10;        }&#10;    }&#10;&#10;    private var feedId: Long = Long.MIN_VALUE&#10;&#10;    override suspend fun doWork(): Result = withContext(dispatchers.io) {&#10;        feedId = inputData.getLong(PARAM_FEED_ID, Long.MIN_VALUE)&#10;        if (feedId == Long.MIN_VALUE) {&#10;            Timber.w(&quot;No feed_id was specified. Skip work&quot;)&#10;            return@withContext Result.success()&#10;        }&#10;        collectNewArticles()&#10;        Result.success()&#10;    }&#10;&#10;    @Throws(ApiCallException::class, RemoteException::class, OperationApplicationException::class)&#10;    private suspend fun collectNewArticles() = coroutineScope {&#10;        val isFreshFeed = feedId == -3L&#10;        // For Fresh Articles (-3), we want all unread items regardless of age.&#10;        // For All Articles (-4) and regular feeds, we limit to 1 day to handle the &quot;catch up&quot; scenario without downloading history.&#10;        val cutoffTime = if (isFreshFeed) 0L else System.currentTimeMillis() / 1000 - TimeUnit.DAYS.toSeconds(1)&#10;        val limitDescription = if (isFreshFeed) &quot;no time limit&quot; else &quot;limit 1 day&quot;&#10;&#10;        Timber.i(&quot;Collecting new articles for feed $feedId ($limitDescription)&quot;)&#10;        val latestId = getLatestArticleId()&#10;&#10;        var offset = 0&#10;        var totalFetched = 0&#10;        val maxArticlesToFetch = 1000&#10;&#10;        // Fetch newest articles first (gradually=false)&#10;        var articlesRaw = getArticles(feedId, latestId, offset,&#10;            includeAttachments = true, gradually = false)&#10;&#10;        while (articlesRaw.isNotEmpty() &amp;&amp; totalFetched &lt; maxArticlesToFetch) {&#10;            // Filter out articles older than cutoff (only applies to non-Fresh feeds)&#10;            val recentArticles = articlesRaw.filter { it.article.lastTimeUpdate &gt;= cutoffTime }&#10;            &#10;            if (recentArticles.isNotEmpty()) {&#10;                databaseService.runInTransaction {&#10;                    insertArticles(recentArticles)&#10;                }&#10;                totalFetched += recentArticles.size&#10;            }&#10;&#10;            // Check if we reached the end of the &quot;fresh&quot; window&#10;            // If the last article in the batch is older than cutoff, we can stop (unless it's Fresh feed where we want all)&#10;            val oldestInBatch = articlesRaw.minByOrNull { it.article.lastTimeUpdate }?.article?.lastTimeUpdate ?: 0&#10;            &#10;            // For regular feeds, stop if we hit old articles. &#10;            // For fresh feed, we technically could stop if we hit something older than we care about, &#10;            // but user said &quot;fetch all unread&quot;, so we continue until maxArticlesToFetch is hit or API is empty.&#10;            if (!isFreshFeed &amp;&amp; oldestInBatch &lt; cutoffTime) {&#10;                Timber.i(&quot;Reached articles older than cutoff. Stopping sync for feed $feedId.&quot;)&#10;                break&#10;            }&#10;&#10;            offset += articlesRaw.size&#10;            &#10;            if (totalFetched &lt; maxArticlesToFetch) {&#10;                articlesRaw = getArticles(feedId, latestId, offset, includeAttachments = true, gradually = false)&#10;            }&#10;        }&#10;    }&#10;&#10;    private suspend fun getLatestArticleId(): Long {&#10;        return databaseService.getLatestArticleIdFromFeed(feedId) ?: 0&#10;    }&#10;&#10;    private suspend fun insertArticles(articles: List&lt;ArticleWithAttachments&gt;) {&#10;        val articlesOnly = articles.map { it.article }&#10;        databaseService.insertArticles(articlesOnly)&#10;        val articlesTags = articlesOnly.flatMap {&#10;            val tags = it.tags.split(&quot;,&quot;)&#10;                .map(String::trim)&#10;                .filter(String::isNotEmpty)&#10;            tags.map {tag -&gt;&#10;                ArticlesTags(it.id, tag)&#10;            }&#10;        }&#10;        databaseService.insertArticleTags(articlesTags)&#10;        val attachments = articles.flatMap { it.attachments }&#10;        databaseService.insertAttachments(attachments)&#10;    }&#10;&#10;    private fun CoroutineScope.cacheArticlesImages(articles: List&lt;Article&gt;) {&#10;        articles.filter {&#10;            it.isUnread&#10;        }.forEach { cacheArticleImages(it) }&#10;    }&#10;&#10;    private fun CoroutineScope.cacheArticleImages(article: Article) {&#10;        if (!backgroundDataUsageManager.canDownloadArticleImages()) {&#10;            return&#10;        }&#10;        imageUrlExtractor.extract(article.content, baseUri = article.link)&#10;                .mapNotNull { it.toHttpUrlOrNull() }&#10;                .filter { it.canBeCache() }&#10;                .forEach {&#10;                    launch(dispatchers.io) {&#10;                        try {&#10;                            httpCacher.cacheHttpRequest(it)&#10;                        } catch (e: IOException) {&#10;                            Timber.w(e, &quot;Unable to cache request $it&quot;)&#10;                        }&#10;                    }&#10;                }&#10;    }&#10;&#10;    private fun HttpUrl.canBeCache(): Boolean {&#10;        if (scheme == &quot;http&quot; &amp;&amp; !NetworkSecurityPolicy.getInstance().isCleartextTrafficPermitted(host)) {&#10;            Timber.d(&quot;Can't cache $this, clear text traffic not permitted&quot;)&#10;            return false&#10;        }&#10;        return true&#10;    }&#10;&#10;}&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>